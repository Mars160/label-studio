title: "Prompt engineering"
type: community
group: Generative AI
order: 3
image: /static/templates/prompt-engineering.png
details: Interactive prompt engineering for generative AI models. It allows you to prompt your LLM and retrieve the generated text on the fly. It works with ML backend from https://github.com/HumanSignal/label-studio-ml-backend/tree/master/label_studio_ml/examples/llm_interactive example.
config: |
  <View>
     <Style>
      .lsf-main-content.lsf-requesting .prompt::before { content: ' loading...'; color: #808080; }
       
      .text-container {
          background-color: white;
          border-radius: 10px;
          box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
          padding: 20px;
          font-family: 'Courier New', monospace;
          line-height: 1.6;
          font-size: 16px;
       }
    </Style>
    <Header value="Context:"/>
    <View className="text-container">
      <Text name="context" value="$text" />
    </View>
    <Header value="Prompt:" />
    <View className="prompt">
      <TextArea name="prompt"
                toName="context"
                rows="4"
                editable="true"
                maxSubmissions="1"
                showSubmitButton="false"
                placeholder="Type your prompt here then Shift+Enter..."
      />
    </View>
    <Header value="Response:"/>
    <TextArea name="response"
              toName="context"
              rows="4"
              editable="true"
              maxSubmissions="1"
              showSubmitButton="false"
              placeholder="Generated response will appear here..."
    />
  </View>
